#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫ MySQL –∏ –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤.
–ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ –∏–ª–∏ –ø–æ –∫—Ä–æ–Ω—É/–¥–µ–º–æ–Ω—É.
"""
import os
import time
from dotenv import load_dotenv
import mysql.connector
from datetime import datetime

if os.path.exists('backend/.env'):
    load_dotenv('backend/.env')
else:
    load_dotenv()

DB_HOST = os.getenv('DB_HOST', 'localhost')
DB_USER = os.getenv('DB_USER', 'root')
DB_PASSWORD = os.getenv('DB_PASSWORD', '')
DB_NAME = os.getenv('DB_NAME', '')

def get_database_metrics(conn):
    cursor = conn.cursor(dictionary=True)
    metrics = {}
    cursor.execute("SHOW STATUS LIKE 'Threads_connected'")
    metrics['active_connections'] = int(cursor.fetchone()['Value'])
    cursor.execute("SHOW STATUS LIKE 'Questions'")
    metrics['total_queries'] = int(cursor.fetchone()['Value'])
    cursor.execute("SHOW STATUS LIKE 'Slow_queries'")
    metrics['slow_queries'] = int(cursor.fetchone()['Value'])
    cursor.execute("SHOW STATUS LIKE 'Uptime'")
    metrics['uptime'] = int(cursor.fetchone()['Value'])
    cursor.execute("""
        SELECT SUM(data_length + index_length) / 1024 / 1024 AS size_mb
        FROM information_schema.tables
        WHERE table_schema = %s
    """, (DB_NAME,))
    res = cursor.fetchone()
    metrics['database_size_mb'] = float(res['size_mb'] or 0) if res else 0.0
    cursor.close()
    return metrics

def analyze_query_patterns(conn):
    cursor = conn.cursor(dictionary=True)
    # –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ: –≤ –≤–∞—à–µ–π –ë–î –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –∏–º—è —Å—Ç–æ–ª–±—Ü–∞ —Å –≤—Ä–µ–º–µ–Ω–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (execution_time / created_at)
    query = """
    SELECT 
        COUNT(*) as total_queries,
        AVG(query_duration_ms) as avg_duration,
        MAX(query_duration_ms) as max_duration,
        SUM(CASE WHEN is_suspicious = 1 THEN 1 ELSE 0 END) as suspicious_count,
        AVG(anomaly_score) as avg_anomaly_score
    FROM query_logs
    WHERE execution_time >= NOW() - INTERVAL 1 HOUR
    """
    try:
        cursor.execute(query)
        result = cursor.fetchone()
    except Exception as e:
        print("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:", e)
        result = {'total_queries': 0, 'avg_duration': None, 'max_duration': None, 'suspicious_count': 0, 'avg_anomaly_score': None}
    cursor.close()
    return result

def detect_anomalies(current_metrics, historical_avg):
    anomalies = []
    if current_metrics['active_connections'] > historical_avg['connections'] * 1.5:
        anomalies.append({'type':'HIGH_CONNECTIONS','severity':'WARNING','message':f"–í—ã—Å–æ–∫–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {current_metrics['active_connections']}"})
    if current_metrics['slow_queries'] > historical_avg['slow_queries'] * 2:
        anomalies.append({'type':'SLOW_QUERIES','severity':'WARNING','message':f"–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {current_metrics['slow_queries']}"})
    return anomalies

def main(iterations=5, pause=10):
    conn = mysql.connector.connect(host=DB_HOST, user=DB_USER, password=DB_PASSWORD, database=DB_NAME)
    historical_avg = {'connections': 10, 'slow_queries': 5}
    for i in range(iterations):
        print("="*60)
        print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ #{i+1} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        metrics = get_database_metrics(conn)
        query_stats = analyze_query_patterns(conn)
        print("\nüìä –ú–ï–¢–†–ò–ö–ò –ë–î:")
        print(f"  –ê–∫—Ç–∏–≤–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {metrics['active_connections']}")
        print(f"  –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {metrics['total_queries']}")
        print(f"  –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã: {metrics['slow_queries']}")
        print(f"  –†–∞–∑–º–µ—Ä –ë–î: {metrics['database_size_mb']:.2f} MB")
        print("\nüîç –ê–ù–ê–õ–ò–ó –ó–ê–ü–†–û–°–û–í (–ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å):")
        if query_stats and query_stats['total_queries']:
            print(f"  –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {query_stats['total_queries']}")
            print(f"  –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {query_stats['avg_duration']}")
            print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {query_stats['max_duration']}")
            print(f"  –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {query_stats['suspicious_count']}")
            print(f"  –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –∞–Ω–æ–º–∞–ª–∏–∏: {query_stats['avg_anomaly_score']}")
        else:
            print("  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å –∏–ª–∏ –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è.")
        anomalies = detect_anomalies(metrics, historical_avg)
        if anomalies:
            print("\n‚ö†Ô∏è  –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ê–ù–û–ú–ê–õ–ò–ò:")
            for a in anomalies:
                print(f"  [{a['severity']}] {a['message']}")
        else:
            print("\n‚úÖ –ê–Ω–æ–º–∞–ª–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        time.sleep(pause)
    conn.close()

if __name__ == "__main__":
    main()